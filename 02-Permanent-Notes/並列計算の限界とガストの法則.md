# 並列計算の限界とガストの法則

## 概要
ガストの法則（Gustafson's Law）は、並列計算におけるスケーラビリティの限界を考える際に、アムダールの法則の補完的な視点を提供します。1988年、ジョン・ガストフソンによって提唱されました。

## ガストの法則の主張
- アムダールの法則は「問題サイズが固定」の前提でスピードアップの限界を論じますが、ガストの法則は「プロセッサ数が増えれば、より大きな問題を同じ時間で解ける」という現実的な状況を想定します。
- 並列化できる部分の割合を $p$、プロセッサ数を $N$ としたとき、ガストの法則によるスピードアップは次式で表されます：

  $$\text{Speedup}_{Gustafson} = N - (1-p) \times (N-1)$$

- これは、プロセッサ数が増えるほど、並列化できる部分が大きくなればスピードアップもほぼ線形に向上しうることを示しています。

## ガストの法則の数式導出
ガストの法則の数式は、以下のような論理で導かれます。

1. **問題設定**
   - 並列計算の現場では「プロセッサ数が増えれば、より大きな問題を同じ時間で解く」ことが現実的です。
   - 全体の処理時間を「1」とし、直列部分の割合を $s$、並列部分の割合を $p$（$s + p = 1$）とします。

2. **各プロセッサの仕事量**
   - 直列部分は全プロセッサで共通して実行するため、各プロセッサが必ず $s$ だけ処理します。
   - 並列部分は $N$ 台で分担し、各プロセッサが $p$ だけ担当します。

3. **全体の仕事量**
   - 各プロセッサが $s + p$ だけ仕事をするので、全体の仕事量は $N(s + p)$ となります。

4. **スピードアップの定義**
   - スピードアップは「1台で処理した場合の仕事量 ÷ 並列化後の最大所要時間」で定義されます。
   - 1台の場合の仕事量は $s + p = 1$。
   - 並列化後の最大所要時間は $s + p$（各プロセッサが同じだけ仕事をする前提）。
   - ただし、全体の仕事量は $N(s + p)$ なので、スピードアップは：

     $$
     \text{Speedup}_{Gustafson} = s + Np
     $$
   - $p = 1 - s$ として整理すると：

     $$
     \text{Speedup}_{Gustafson} = N - s(N-1)
     $$
   - これがガストの法則の数式です。

---

### 補足・批判的視点
- この導出は「各プロセッサが同じだけ仕事を分担できる」「オーバーヘッドがない」理想的な状況を仮定しています。
- 実際には通信・同期コストや負荷分散の偏りが生じるため、理論値よりスピードアップは小さくなります。

## 具体例
- 80%が並列化可能な処理（$p=0.8$）を4台のプロセッサで実行する場合：

  $$\text{Speedup}_{Gustafson} = 4 - 0.2 \times 3 = 3.4$$

- アムダールの法則では最大2.5倍でしたが、ガストの法則では3.4倍と、より現実的なスケーラビリティを示します。

## 批判的視点・限界
- ガストの法則も理想的な並列化（オーバーヘッドなし）を仮定しており、現実には通信・同期コストが無視できません。
- 問題サイズの増加が常に有効とは限らず、メモリやI/Oなど他の資源がボトルネックになる場合もあります。

## アムダールの法則との比較
- アムダールの法則：問題サイズ固定、並列化できない部分がボトルネック
- ガストの法則：問題サイズ可変、プロセッサ数増加でスケーラビリティ向上

## 関連ノート・リンク案
- [[アムダールの法則とは何か]]
- [[分散処理におけるオーバーヘッド]]
- [[プロセッサ数とスケーラビリティの関係]]

## タグ
#スケーラビリティ #計算機アーキテクチャ


[//begin]: # "Autogenerated link references for markdown compatibility"
[アムダールの法則とは何か]: 02-Permanent-Notes/%E3%82%A2%E3%83%A0%E3%83%80%E3%83%BC%E3%83%AB%E3%81%AE%E6%B3%95%E5%89%87%E3%81%A8%E3%81%AF%E4%BD%95%E3%81%8B.md "アムダールの法則とは何か"
[//end]: # "Autogenerated link references"
